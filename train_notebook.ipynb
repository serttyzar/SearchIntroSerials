{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12173483,"sourceType":"datasetVersion","datasetId":7655728}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom tqdm import tqdm\nimport random\nimport numpy as np\nimport os\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom scipy.ndimage import label as scipy_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.160243Z","iopub.execute_input":"2025-06-15T13:31:15.160622Z","iopub.status.idle":"2025-06-15T13:31:15.165714Z","shell.execute_reply.started":"2025-06-15T13:31:15.160593Z","shell.execute_reply":"2025-06-15T13:31:15.164808Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"seed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.167067Z","iopub.execute_input":"2025-06-15T13:31:15.167328Z","iopub.status.idle":"2025-06-15T13:31:15.181235Z","shell.execute_reply.started":"2025-06-15T13:31:15.167310Z","shell.execute_reply":"2025-06-15T13:31:15.180674Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass CRF(nn.Module):\n    \"\"\"\n    Реализация Conditional Random Field (CRF) (были проблемы с импортом)\n    \"\"\"\n    def __init__(self, num_tags: int, batch_first: bool = True):\n        if num_tags <= 0:\n            raise ValueError(f\"invalid number of tags: {num_tags}\")\n        super().__init__()\n        self.num_tags = num_tags\n        self.batch_first = batch_first\n        self.transitions = nn.Parameter(torch.empty(num_tags, num_tags))\n        self.start_transitions = nn.Parameter(torch.empty(num_tags))\n        self.end_transitions = nn.Parameter(torch.empty(num_tags))\n        nn.init.uniform_(self.transitions, -0.1, 0.1)\n        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n\n    def forward(self, emissions, tags=None, mask=None, reduction: str = 'mean'):\n        if self.batch_first:\n            emissions = emissions.transpose(0, 1)\n            if tags is not None:\n                tags = tags.transpose(0, 1)\n            if mask is not None:\n                mask = mask.transpose(0, 1)\n        if mask is None:\n            mask = torch.ones_like(tags, dtype=torch.uint8)\n        log_likelihood = self._compute_log_likelihood(emissions, tags, mask)\n        if reduction == 'sum':\n            return -log_likelihood.sum()\n        if reduction == 'mean':\n            return -log_likelihood.mean()\n        return -log_likelihood\n\n    def decode(self, emissions, mask=None):\n        if self.batch_first:\n            emissions = emissions.transpose(0, 1)\n            if mask is not None:\n                mask = mask.transpose(0, 1)\n        if mask is None:\n            mask = torch.ones(emissions.shape[:2], dtype=torch.uint8, device=emissions.device)\n        return self._viterbi_decode(emissions, mask)\n\n    def _compute_log_likelihood(self, emissions, tags, mask):\n        seq_length, batch_size, _ = emissions.shape\n        log_alpha = self._forward_pass(emissions, mask)\n        gold_score = self._score_sequence(emissions, tags, mask)    \n        return gold_score - log_alpha\n\n    def _forward_pass(self, emissions, mask):\n        seq_length, batch_size, _ = emissions.shape\n        log_alpha = self.start_transitions + emissions[0]\n        for i in range(1, seq_length):\n            emit_scores = emissions[i].unsqueeze(1)\n            trans_scores = self.transitions.unsqueeze(0)\n            alpha_t = log_alpha.unsqueeze(2)\n            scores = trans_scores + alpha_t + emit_scores\n            log_alpha_next = torch.logsumexp(scores, dim=1)\n            mask_t = mask[i].unsqueeze(1).float()\n            log_alpha = mask_t * log_alpha_next + (1 - mask_t) * log_alpha\n        log_alpha += self.end_transitions\n        return torch.logsumexp(log_alpha, dim=1)\n\n\n    def _score_sequence(self, emissions, tags, mask):\n        batch_size = emissions.size(1)\n        score = self.start_transitions[tags[0]]\n        score += (emissions.gather(2, tags.unsqueeze(2)).squeeze(2) * mask.float()).sum(0)\n        for i in range(emissions.size(0) - 1):\n            score += self.transitions[tags[i], tags[i+1]] * mask[i+1].float()\n        seq_ends = mask.long().sum(dim=0) - 1\n        last_tags = tags[seq_ends, torch.arange(batch_size)]\n        score += self.end_transitions[last_tags]\n        return score\n    \n    def _viterbi_decode(self, emissions, mask):\n        seq_length, batch_size, _ = emissions.shape\n        log_delta = self.start_transitions + emissions[0]\n        backpointers = []\n        for i in range(1, seq_length):\n            delta_t = log_delta.unsqueeze(2)\n            trans_scores = self.transitions.unsqueeze(0)\n            scores = delta_t + trans_scores\n            log_delta_next, backpointers_t = torch.max(scores, dim=1)\n            log_delta_next += emissions[i]\n            mask_t = mask[i].unsqueeze(1).float()\n            log_delta = mask_t * log_delta_next + (1 - mask_t) * log_delta\n            backpointers.append(backpointers_t)\n\n        log_delta += self.end_transitions\n        best_last_tag = torch.argmax(log_delta, dim=1)\n        best_path = [best_last_tag]\n        for backpointers_t in reversed(backpointers):\n            best_last_tag = backpointers_t.gather(1, best_last_tag.unsqueeze(1)).squeeze(1)\n            best_path.insert(0, best_last_tag)    \n        return torch.stack(best_path).transpose(0, 1).tolist()\n\n\nclass IntroDetectionTransformer(nn.Module):\n    def __init__(self, d_model=768, n_heads=8, n_layers=4, num_labels=2, class_weights=None):\n        super().__init__()\n        self.pos_encoding = nn.Parameter(torch.zeros(1, 60, d_model))\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, batch_first=True, dropout=0.1)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.classifier = nn.Linear(d_model, num_labels)\n        self.crf = CRF(num_labels, batch_first=True)\n    \n        if class_weights is not None:\n            self.register_buffer('class_weights', class_weights)\n        else:\n            self.class_weights = None\n\n    def forward(self, embeddings, labels=None, mask=None):\n        x = embeddings + self.pos_encoding\n        x = self.transformer(x) \n        logits = self.classifier(x)\n\n        if labels is not None:\n            if self.class_weights is not None:\n                logits[:, :, 1] = logits[:, :, 1] * self.class_weights[1]\n            \n            return self.crf(logits, labels.long(), mask=mask)\n        else:\n            return self.crf.decode(logits, mask=mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.263925Z","iopub.execute_input":"2025-06-15T13:31:15.264230Z","iopub.status.idle":"2025-06-15T13:31:15.288362Z","shell.execute_reply.started":"2025-06-15T13:31:15.264209Z","shell.execute_reply":"2025-06-15T13:31:15.287737Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"dataset = VideoDataset('/kaggle/input/introdetectiondataset/train_dataset2.pt')\n# labels = [1.0 if any(item[\"labels\"] == 1) else 0.0 for item in dataset.data]\n# weights = [20.0 if label == 1 else 1.0 for label in labels]  # Oversampling для заставок\n# sampler = WeightedRandomSampler(weights, len(dataset), replacement=True)\ndataloader = DataLoader(dataset, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.290018Z","iopub.execute_input":"2025-06-15T13:31:15.290498Z","iopub.status.idle":"2025-06-15T13:31:15.347597Z","shell.execute_reply.started":"2025-06-15T13:31:15.290478Z","shell.execute_reply":"2025-06-15T13:31:15.347010Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"print(f\"Количество окон: {len(dataset)}\")\nhas_positive = any(any(item[1] == 1) for item in dataset)\nprint(f\"Есть ли кадры заставки (метка 1): {has_positive}\")\npositive_windows = sum(1 for item in dataset if any(item[1] == 1))\nprint(f\"Количество окон с кадрами заставки: {positive_windows}\")\ntotal_positive_frames = sum(item[1].sum().item() for item in dataset)\nprint(f\"Общее количество кадров с меткой 1: {total_positive_frames}\")\nprint(f\"Доля кадров с меткой 1: {total_positive_frames / (len(dataset) * 60):.4%}\")\nif len(dataset) > 0:\n    print(f\"Размерность эмбеддингов: {dataset[0][0].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.348474Z","iopub.execute_input":"2025-06-15T13:31:15.348755Z","iopub.status.idle":"2025-06-15T13:31:15.375785Z","shell.execute_reply.started":"2025-06-15T13:31:15.348733Z","shell.execute_reply":"2025-06-15T13:31:15.375025Z"}},"outputs":[{"name":"stdout","text":"Количество окон: 149\nЕсть ли кадры заставки (метка 1): True\nКоличество окон с кадрами заставки: 64\nОбщее количество кадров с меткой 1: 412.0\nДоля кадров с меткой 1: 4.6085%\nРазмерность эмбеддингов: torch.Size([60, 768])\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Training on device: {device}\")\n\n\nd_model = 768\nclass_weights = torch.tensor([1.0, 2.0])  # Интро важнее\nmodel = IntroDetectionTransformer(d_model=d_model, n_heads=12, n_layers=6, num_labels=2, class_weights=class_weights).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-5, weight_decay=1e-5)\n\ntorch.nn.TransformerEncoder.use_nested_tensor = False\n\nnum_epochs = 30\nmodel.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for embeddings, labels in tqdm(dataloader, desc=f\"Эпоха {epoch+1}/{num_epochs}\"):\n        embeddings, labels = embeddings.to(device), labels.to(device)\n        mask = torch.ones(embeddings.shape[0], 60, device=device).bool()\n        optimizer.zero_grad()\n        loss = model(embeddings, labels, mask)\n        if loss.dim() > 0:\n            loss = loss.mean()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Эпоха {epoch+1}, Средняя потеря: {total_loss / len(dataloader):.4f}\")\n\nmodel_path = os.path.join('/kaggle/working/', \"model.pt\")\ntorch.save(model.state_dict(), model_path)\nprint(f\"Модель сохранена в {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:15.376701Z","iopub.execute_input":"2025-06-15T13:31:15.376977Z","iopub.status.idle":"2025-06-15T13:31:47.041312Z","shell.execute_reply.started":"2025-06-15T13:31:15.376960Z","shell.execute_reply":"2025-06-15T13:31:47.040411Z"}},"outputs":[{"name":"stdout","text":"Training on device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 1/30: 100%|██████████| 10/10 [00:01<00:00,  9.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 1, Средняя потеря: 24.1686\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 2/30: 100%|██████████| 10/10 [00:01<00:00,  9.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 2, Средняя потеря: 12.5975\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 3/30: 100%|██████████| 10/10 [00:00<00:00, 10.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 3, Средняя потеря: 10.2740\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 4/30: 100%|██████████| 10/10 [00:00<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 4, Средняя потеря: 9.4076\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 5/30: 100%|██████████| 10/10 [00:01<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 5, Средняя потеря: 8.7030\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 6/30: 100%|██████████| 10/10 [00:01<00:00,  9.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 6, Средняя потеря: 8.0098\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 7/30: 100%|██████████| 10/10 [00:00<00:00, 10.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 7, Средняя потеря: 7.2284\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 8/30: 100%|██████████| 10/10 [00:01<00:00,  9.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 8, Средняя потеря: 6.7306\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 9/30: 100%|██████████| 10/10 [00:01<00:00,  9.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 9, Средняя потеря: 6.2217\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 10/30: 100%|██████████| 10/10 [00:01<00:00,  9.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 10, Средняя потеря: 5.6213\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 11/30: 100%|██████████| 10/10 [00:01<00:00,  9.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 11, Средняя потеря: 5.1102\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 12/30: 100%|██████████| 10/10 [00:01<00:00,  9.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 12, Средняя потеря: 5.4195\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 13/30: 100%|██████████| 10/10 [00:01<00:00,  9.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 13, Средняя потеря: 5.8463\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 14/30: 100%|██████████| 10/10 [00:01<00:00,  9.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 14, Средняя потеря: 7.2038\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 15/30: 100%|██████████| 10/10 [00:01<00:00,  9.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 15, Средняя потеря: 7.6556\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 16/30: 100%|██████████| 10/10 [00:01<00:00,  9.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 16, Средняя потеря: 4.9552\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 17/30: 100%|██████████| 10/10 [00:01<00:00,  9.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 17, Средняя потеря: 4.7068\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 18/30: 100%|██████████| 10/10 [00:01<00:00,  9.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 18, Средняя потеря: 3.6334\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 19/30: 100%|██████████| 10/10 [00:01<00:00,  9.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 19, Средняя потеря: 3.3308\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 20/30: 100%|██████████| 10/10 [00:01<00:00,  9.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 20, Средняя потеря: 3.0314\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 21/30: 100%|██████████| 10/10 [00:01<00:00,  9.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 21, Средняя потеря: 2.7904\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 22/30: 100%|██████████| 10/10 [00:01<00:00,  9.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 22, Средняя потеря: 2.9009\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 23/30: 100%|██████████| 10/10 [00:01<00:00,  9.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 23, Средняя потеря: 2.4651\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 24/30: 100%|██████████| 10/10 [00:01<00:00,  9.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 24, Средняя потеря: 2.3119\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 25/30: 100%|██████████| 10/10 [00:01<00:00,  9.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 25, Средняя потеря: 2.3643\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 26/30: 100%|██████████| 10/10 [00:01<00:00,  9.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 26, Средняя потеря: 2.5779\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 27/30: 100%|██████████| 10/10 [00:01<00:00,  9.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 27, Средняя потеря: 2.5489\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 28/30: 100%|██████████| 10/10 [00:01<00:00,  9.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 28, Средняя потеря: 1.8679\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 29/30: 100%|██████████| 10/10 [00:01<00:00,  9.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 29, Средняя потеря: 1.5295\n","output_type":"stream"},{"name":"stderr","text":"Эпоха 30/30: 100%|██████████| 10/10 [00:01<00:00,  9.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Эпоха 30, Средняя потеря: 2.4235\nМодель сохранена в /kaggle/working/model.pt\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"class VideoDataset2(Dataset):\n    def __init__(self, dataset_path):\n        self.data = torch.load(dataset_path)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        return item[\"embeddings\"], item[\"labels\"], item[\"video_id\"], item[\"window_start_frame_idx\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:31:47.042989Z","iopub.execute_input":"2025-06-15T13:31:47.043240Z","iopub.status.idle":"2025-06-15T13:31:47.048554Z","shell.execute_reply.started":"2025-06-15T13:31:47.043221Z","shell.execute_reply":"2025-06-15T13:31:47.047696Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from scipy.ndimage import label as scipy_label\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nfrom scipy.ndimage import binary_closing\n\n\ndef calculate_iou(pred_start, pred_end, true_start, true_end):\n    intersection_start = max(pred_start, true_start)\n    intersection_end = min(pred_end, true_end)\n    intersection = max(0, intersection_end - intersection_start)\n    union = (pred_end - pred_start) + (true_end - true_start) - intersection\n    return intersection / union if union > 0 else 0.0\n\n\ntest_dataset_path = '/kaggle/input/introdetectiondataset/test_dataset2.pt'\ntest_dataset = VideoDataset2(test_dataset_path)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nd_model = 768\n#+ Передаем num_labels=2\nmodel = IntroDetectionTransformer(d_model=d_model, n_heads=12, n_layers=6, num_labels=2, class_weights=class_weights).to(device)\nmodel_path = '/kaggle/working/model.pt'\nmodel.load_state_dict(torch.load(model_path))\nmodel.eval()\n\n#+ all_probs больше не существует, будут all_preds\nall_preds_raw = [] # Для исходных предсказаний\nall_preds_closed = [] # Для обработанных предсказаний\nall_labels = []\nvideo_predictions = {}\nvideo_ground_truth = {}\n\nwith torch.no_grad():\n    print(\"Исходные переходы CRF:\\n\", model.crf.transitions.data)\n    \n    boost_self_transition = 1.5  # Увеличиваем вероятность остаться в состоянии \"заставка\"\n    penalize_exit_transition = -1.5 # Уменьшаем вероятность выйти из состояния \"заставка\"\n\n    # Сохраняем оригинальные веса\n    original_transitions = model.crf.transitions.data.clone()\n    \n    model.crf.transitions.data[1, 1] += boost_self_transition\n    model.crf.transitions.data[1, 0] += penalize_exit_transition\n    \n    print(\"\\nИзмененные переходы CRF:\\n\", model.crf.transitions.data)\n    for embeddings, labels, video_ids, start_indices in tqdm(test_dataloader, desc=\"Оценка\"):\n        if embeddings.shape[0] <= 1:\n            print(f\"Пропущен батч размером {embeddings.shape[0]} для стабильности.\")\n            continue\n        embeddings = embeddings.to(device)\n        mask = torch.ones(embeddings.shape[0], 60, device=device, dtype=torch.bool)\n\n        predicted_sequences = model(embeddings, mask=mask)\n        \n        predicted_labels = np.array(predicted_sequences)\n        true_labels = labels.cpu().numpy()\n        closed_labels_batch = []\n        for pred_seq in predicted_labels:\n            closed_labels_batch.append(binary_closing(pred_seq, structure=np.ones(3)).astype(int))\n        closed_labels_batch = np.array(closed_labels_batch)\n        \n        all_preds_raw.append(predicted_labels)\n        all_preds_closed.append(closed_labels_batch)\n        all_labels.append(true_labels)\n        \n        for i, (video_id, start_idx, pred_seq_closed, true_seq) in enumerate(zip(video_ids, start_indices, closed_labels_batch, true_labels)):\n            start_idx = start_idx.item()\n            if video_id not in video_predictions:\n                video_predictions[video_id] = []\n                video_ground_truth[video_id] = []\n\n            labeled_preds, num_groups = scipy_label(pred_seq_closed)\n            for group in range(1, num_groups + 1):\n                indices = np.where(labeled_preds == group)[0]\n                if len(indices) >= 3:\n                    start_sec = start_idx + indices[0]\n                    end_sec = start_idx + indices[-1] + 1\n                    video_predictions[video_id].append((start_sec, end_sec))\n\n            labeled_trues, num_true_groups = scipy_label(true_seq)\n            for group in range(1, num_true_groups + 1):\n                indices = np.where(labeled_trues == group)[0]\n                if indices.size > 0:\n                    start_sec = start_idx + indices[0]\n                    end_sec = start_idx + indices[-1] + 1\n                    if (start_sec, end_sec) not in video_ground_truth.get(video_id, []):\n                         video_ground_truth[video_id].append((start_sec, end_sec))\n    model.crf.transitions.data = original_transitions\n\n\nall_preds_raw_flat = np.concatenate(all_preds_raw).flatten()\nall_labels_flat = np.concatenate(all_labels).flatten()\n\nprint(\"\\n--- Метрики ДО постобработки ---\")\nprint(f\"Precision: {precision_score(all_labels_flat, all_preds_raw_flat, zero_division=0):.4f}\")\nprint(f\"Recall:    {recall_score(all_labels_flat, all_preds_raw_flat, zero_division=0):.4f}\")\nprint(f\"F1-мера:   {f1_score(all_labels_flat, all_preds_raw_flat, zero_division=0):.4f}\")\n\n\nall_preds_closed_flat = np.concatenate(all_preds_closed).flatten()\n\nprint(\"\\n--- Метрики ПОСЛЕ постобработки (binary_closing) ---\")\nprint(f\"Precision: {precision_score(all_labels_flat, all_preds_closed_flat, zero_division=0):.4f}\")\nprint(f\"Recall:    {recall_score(all_labels_flat, all_preds_closed_flat, zero_division=0):.4f}\")\nprint(f\"F1-мера:   {f1_score(all_labels_flat, all_preds_closed_flat, zero_division=0):.4f}\")\n \niou_scores = []\nfor video_id in video_predictions:\n    pred_intervals = video_predictions.get(video_id, [])\n    true_intervals = video_ground_truth.get(video_id, [])\n    if not true_intervals:\n        continue\n    for pred in pred_intervals:\n        for true in true_intervals:\n            iou = calculate_iou(pred[0], pred[1], true[0], true[1])\n            iou_scores.append(iou)\n\nmean_iou = np.mean(iou_scores) if iou_scores else 0.0\nprint(\"\\nМетрики на уровне интервалов:\")\nprint(f\"Средний IoU: {mean_iou:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:34:03.612790Z","iopub.execute_input":"2025-06-15T13:34:03.613616Z","iopub.status.idle":"2025-06-15T13:34:03.945220Z","shell.execute_reply.started":"2025-06-15T13:34:03.613590Z","shell.execute_reply":"2025-06-15T13:34:03.944242Z"}},"outputs":[{"name":"stdout","text":"Исходные переходы CRF:\n tensor([[ 0.0791,  0.0579],\n        [-0.0193,  0.0196]], device='cuda:0')\n\nИзмененные переходы CRF:\n tensor([[ 0.0791,  0.0579],\n        [-1.5193,  1.5196]], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Оценка: 100%|██████████| 3/3 [00:00<00:00, 31.78it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Метрики ДО постобработки ---\nPrecision: 0.6536\nRecall:    0.7752\nF1-мера:   0.7092\n\n--- Метрики ПОСЛЕ постобработки (binary_closing) ---\nPrecision: 0.6586\nRecall:    0.7726\nF1-мера:   0.7111\n\nМетрики на уровне интервалов:\nСредний IoU: 0.6295\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink('model.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:34:25.372428Z","iopub.execute_input":"2025-06-15T13:34:25.372718Z","iopub.status.idle":"2025-06-15T13:34:25.378902Z","shell.execute_reply.started":"2025-06-15T13:34:25.372697Z","shell.execute_reply":"2025-06-15T13:34:25.378198Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.pt","text/html":"<a href='model.pt' target='_blank'>model.pt</a><br>"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}